"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[5766],{8585:o=>{o.exports=JSON.parse('{"tag":{"label":"robotics","permalink":"/physical-ai-humanoid-textbook/tags/robotics","allTagsPath":"/physical-ai-humanoid-textbook/tags","count":2,"items":[{"id":"modules/module-4-vision-language-action/llm-robotics-convergence","title":"LLM-Robotics Convergence","description":"Understanding how Large Language Models (LLMs) converge with robotics to enable natural language interaction with humanoid robots.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/llm-robotics-convergence"},{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"Module 4 - Vision-Language-Action (VLA)","description":"Introduction to Vision-Language-Action (VLA) systems, covering LLM-robotics convergence, voice-to-action, cognitive planning, and complete VLA pipeline integration.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/"}],"unlisted":false}}')}}]);