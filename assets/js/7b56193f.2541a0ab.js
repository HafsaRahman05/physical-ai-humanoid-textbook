"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[160],{7699:i=>{i.exports=JSON.parse('{"tag":{"label":"vision-language-action","permalink":"/physical-ai-humanoid-textbook/tags/vision-language-action","allTagsPath":"/physical-ai-humanoid-textbook/tags","count":1,"items":[{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"Module 4 - Vision-Language-Action (VLA)","description":"Introduction to Vision-Language-Action (VLA) systems, covering LLM-robotics convergence, voice-to-action, cognitive planning, and complete VLA pipeline integration.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/"}],"unlisted":false}}')}}]);