"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[7184],{2691:i=>{i.exports=JSON.parse('{"tag":{"label":"cognitive-planning","permalink":"/physical-ai-humanoid-textbook/tags/cognitive-planning","allTagsPath":"/physical-ai-humanoid-textbook/tags","count":4,"items":[{"id":"modules/module-4-vision-language-action/capstone-project","title":"Capstone Project - The Autonomous Humanoid","description":"Complete VLA pipeline demonstration showing how a simulated humanoid robot receives voice commands, plans paths, navigates obstacles, identifies objects, and manipulates them.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/capstone-project"},{"id":"modules/module-4-vision-language-action/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Understanding how LLMs perform cognitive planning by translating natural language commands into ROS 2 action sequences.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/cognitive-planning"},{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"Module 4 - Vision-Language-Action (VLA)","description":"Introduction to Vision-Language-Action (VLA) systems, covering LLM-robotics convergence, voice-to-action, cognitive planning, and complete VLA pipeline integration.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/"},{"id":"modules/module-4-vision-language-action/safety-validation","title":"Safety & Validation of LLM-Generated Plans","description":"Understanding how LLM-generated action plans are validated and executed safely, including plan verification and constraint checking.","permalink":"/physical-ai-humanoid-textbook/modules/module-4-vision-language-action/safety-validation"}],"unlisted":false}}')}}]);